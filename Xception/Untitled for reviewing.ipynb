{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import time,sys,cv2,datetime,os,math\n",
    "import tensorflow as tf\n",
    "import array as arr\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as image\n",
    "%matplotlib inline\n",
    "%load_ext tensorboard\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import MaxPool2D, GlobalAveragePooling2D, BatchNormalization, MaxPooling2D, Conv2D\n",
    "from tensorflow.keras.layers import Activation, Flatten, Dropout, Dense, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.xception import decode_predictions\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "from tensorflow.keras.applications.xception import Xception, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/project/dogs/Images'\n",
    "num_of_categories = 120\n",
    "image_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 breeds\n"
     ]
    }
   ],
   "source": [
    "breed_list = sorted(os.listdir(image_path))\n",
    "num_classes = len(breed_list)\n",
    "print(\"{} breeds\".format(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_maps = {}\n",
    "label_maps_rev = {}\n",
    "for i, v in enumerate(breed_list):\n",
    "    label_maps.update({v: i})\n",
    "    label_maps_rev.update({i : v})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paths_and_labels():\n",
    "    pic_paths = list()\n",
    "    eng_labels = list()\n",
    "    num_labels = list()\n",
    "    for breed in breed_list:\n",
    "#         print(breed)\n",
    "        base_name = \"/project/dogs/Images/{}/\".format(breed)\n",
    "        for img_name in os.listdir(base_name):\n",
    "            pic_paths.append(base_name + img_name)\n",
    "            eng_labels.append(breed.split(\"-\",1)[1])\n",
    "            num_labels.append(label_maps[breed])\n",
    "    return pic_paths, eng_labels, np.asarray(num_labels)\n",
    "# np.asarray(a)\n",
    "pic_paths, eng_labels, num_labels = paths_and_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageGenerator(Sequence):   \n",
    "    def __init__(self, paths, targets, batch_size, shape, augment=False):\n",
    "        self.paths = paths\n",
    "        self.targets = targets\n",
    "        self.batch_size = batch_size\n",
    "        self.shape = shape\n",
    "        self.augment = augment\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.paths) / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_paths = self.paths[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
    "        x = np.zeros((len(batch_paths), self.shape[0], self.shape[1], self.shape[2]), dtype=np.float32)\n",
    "        y = np.zeros((self.batch_size))\n",
    "        for i, path in enumerate(batch_paths):\n",
    "            x[i] = self.__load_image(path)\n",
    "        y = self.targets[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
    "        return x, y\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for item in (self[i] for i in range(len(self))):\n",
    "            yield item\n",
    "            \n",
    "    def __load_image(self, path):\n",
    "        image = cv2.imread(path)\n",
    "        image = preprocess_input(image)\n",
    "        if self.augment:\n",
    "            sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "            seq = iaa.Sequential([\n",
    "                iaa.OneOf([\n",
    "                    iaa.Fliplr(0.5),\n",
    "            iaa.Flipud(0.5),\n",
    "                    iaa.Crop(percent=(0, 0.1)),\n",
    "                    iaa.Sometimes(0.5,),\n",
    "                    iaa.LinearContrast((0.75, 1.5)),\n",
    "                    iaa.Affine(\n",
    "                        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "                        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "                        rotate=(-45, 45),\n",
    "                        shear=(-8, 8)\n",
    "                    )\n",
    "                ])\n",
    "            ], random_order=True)\n",
    "            image = seq.augment_image(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(pic_paths, num_labels\n",
    "                                                    , test_size=0.2, random_state=0, stratify = num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "x_train,y_train = shuffle(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 32\n",
    "train_ds = ImageGenerator(x_train, y_train, batch_size=batch, shape=(image_size, image_size,3), augment=True)\n",
    "test_ds = ImageGenerator(x_test, y_test, batch_size=batch, shape=(image_size, image_size,3), augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.xception.Xception(weights='imagenet',include_top=False, pooling='avg')#Summary of Xception Model\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_dim = 5 * 5 * 2048\n",
    "\n",
    "model = Sequential(base_model)\n",
    "model.add(Dense(1032, activation='relu',input_dim=flat_dim))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation=None))\n",
    "# model.add(Lambda(lambda x: tf.math.l2_normalize(x, axis=1)))\n",
    "model.add(Dense(120, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_init = 5e-05\n",
    "###################\n",
    "def lr_scheduler(epoch):\n",
    "    epoch += 1\n",
    "    if epoch == 1:\n",
    "        return learning_rate_init\n",
    "    \n",
    "    elif epoch >= 2 and epoch <= 40:\n",
    "        return (0.2*epoch**3)*math.exp(-0.45*epoch)*learning_rate_init\n",
    "    \n",
    "    else:\n",
    "        return lr_scheduler(40-1)\n",
    "stage = [i for i in range(0,25)]\n",
    "learning_rate = [lr_scheduler(x) for x in stage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience = 6, mode='max', min_delta=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(\"weights2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              optimizer = tf.keras.optimizers.RMSprop(lr=5e-05),\n",
    "              metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model:  133\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 90\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable =  False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Model)             (None, 2048)              20861480  \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1032)              2114568   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1032)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               528896    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 120)               30840     \n",
      "=================================================================\n",
      "Total params: 23,732,904\n",
      "Trainable params: 13,963,744\n",
      "Non-trainable params: 9,769,160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"weights2.1_ft.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 19s 189ms/step - loss: 0.4593 - accuracy: 0.8644\n",
      "Test results \n",
      " Loss: 0.4592818021774292 \n",
      " Accuracy 0.8643749952316284\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_ds,steps=int(100))\n",
    "\n",
    "print(\"Test results \\n Loss:\",test_loss,'\\n Accuracy',test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(x_test)/batch\n",
    "predict = model.predict(test_ds,steps=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_cls_idx = predict.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.81      0.87      0.84        30\\n           1       0.83      0.92      0.87        37\\n           2       0.89      0.84      0.87        50\\n           3       0.96      0.87      0.91        30\\n           4       0.81      0.88      0.84        43\\n           5       0.94      0.89      0.92        38\\n           6       0.97      0.92      0.95        39\\n           7       0.93      0.82      0.87        34\\n           8       0.71      0.74      0.72        34\\n           9       0.98      0.98      0.98        48\\n          10       0.88      0.86      0.87        35\\n          11       0.79      0.87      0.83        39\\n          12       1.00      0.97      0.99        37\\n          13       0.83      0.71      0.76        34\\n          14       0.97      0.91      0.94        32\\n          15       0.80      0.65      0.71        31\\n          16       0.77      0.75      0.76        32\\n          17       0.70      0.77      0.73        30\\n          18       0.91      0.97      0.94        30\\n          19       0.88      0.68      0.77        44\\n          20       0.77      0.83      0.80        36\\n          21       0.76      0.76      0.76        37\\n          22       0.87      0.89      0.88        38\\n          23       0.95      0.97      0.96        39\\n          24       0.87      0.90      0.89        30\\n          25       0.95      0.90      0.92        40\\n          26       0.80      0.87      0.83        46\\n          27       0.81      0.94      0.87        32\\n          28       0.76      0.61      0.68        31\\n          29       0.72      0.70      0.71        33\\n          30       0.95      1.00      0.97        36\\n          31       0.94      0.97      0.96        34\\n          32       0.92      0.94      0.93        36\\n          33       0.75      0.79      0.77        34\\n          34       0.82      0.91      0.86        34\\n          35       0.87      0.73      0.79        37\\n          36       0.65      0.85      0.74        33\\n          37       0.76      0.94      0.84        31\\n          38       0.86      0.64      0.74        39\\n          39       0.98      0.98      0.98        41\\n          40       0.82      0.80      0.81        40\\n          41       0.89      0.79      0.84        39\\n          42       0.93      0.69      0.79        39\\n          43       0.94      0.94      0.94        36\\n          44       0.95      0.97      0.96        37\\n          45       0.67      0.94      0.78        31\\n          46       0.81      0.84      0.83        31\\n          47       0.85      0.55      0.67        31\\n          48       0.94      0.97      0.95        32\\n          49       0.88      0.93      0.90        41\\n          50       0.81      0.68      0.74        37\\n          51       0.65      0.84      0.73        31\\n          52       0.85      0.97      0.90        34\\n          53       0.72      0.76      0.74        37\\n          54       0.90      0.93      0.92        30\\n          55       0.85      0.93      0.89        30\\n          56       0.93      0.87      0.90        30\\n          57       0.88      0.82      0.85        34\\n          58       0.88      0.88      0.88        33\\n          59       0.74      0.93      0.82        30\\n          60       0.83      0.81      0.82        31\\n          61       0.91      0.66      0.76        32\\n          62       0.76      0.94      0.84        31\\n          63       0.93      0.90      0.92        31\\n          64       0.81      0.83      0.82        30\\n          65       0.97      0.97      0.97        30\\n          66       0.80      1.00      0.89        32\\n          67       0.80      0.93      0.86        30\\n          68       0.90      0.88      0.89        32\\n          69       0.93      0.93      0.93        30\\n          70       0.94      1.00      0.97        30\\n          71       1.00      0.97      0.98        30\\n          72       0.90      0.90      0.90        31\\n          73       0.85      0.97      0.91        30\\n          74       0.92      0.73      0.81        30\\n          75       0.96      0.81      0.88        31\\n          76       0.68      0.84      0.75        31\\n          77       1.00      0.94      0.97        31\\n          78       0.92      0.97      0.94        34\\n          79       0.78      0.91      0.84        32\\n          80       0.85      0.35      0.50        31\\n          81       0.67      0.87      0.75        30\\n          82       0.79      0.77      0.78        30\\n          83       0.90      0.93      0.92        30\\n          84       1.00      0.80      0.89        30\\n          85       1.00      0.90      0.95        30\\n          86       0.87      0.92      0.89        37\\n          87       0.93      0.79      0.86        34\\n          88       0.91      0.95      0.93        44\\n          89       0.72      0.60      0.65        30\\n          90       0.73      0.90      0.81        40\\n          91       0.79      0.90      0.84        30\\n          92       1.00      0.87      0.93        31\\n          93       1.00      0.80      0.89        30\\n          94       0.94      0.97      0.95        32\\n          95       0.82      0.90      0.86        31\\n          96       1.00      0.94      0.97        34\\n          97       0.79      0.37      0.50        30\\n          98       0.80      0.78      0.79        36\\n          99       0.57      0.87      0.69        38\\n         100       0.90      0.90      0.90        30\\n         101       1.00      0.83      0.91        42\\n         102       0.95      1.00      0.98        40\\n         103       0.89      0.98      0.93        42\\n         104       0.95      0.95      0.95        39\\n         105       0.95      0.95      0.95        43\\n         106       0.98      0.98      0.98        44\\n         107       0.90      0.98      0.93        44\\n         108       1.00      0.90      0.95        39\\n         109       1.00      0.94      0.97        32\\n         110       1.00      1.00      1.00        31\\n         111       0.89      0.89      0.89        36\\n         112       0.90      0.87      0.89        31\\n         113       0.77      0.57      0.65        30\\n         114       0.56      0.77      0.65        31\\n         115       0.93      0.84      0.89        32\\n         116       0.97      0.90      0.93        31\\n         117       0.85      0.90      0.88        31\\n         118       0.96      0.90      0.93        30\\n         119       0.97      0.97      0.97        34\\n\\n    accuracy                           0.86      4116\\n   macro avg       0.87      0.86      0.86      4116\\nweighted avg       0.87      0.86      0.86      4116\\n'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_test,preds_cls_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
