{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time,sys,cv2,datetime,os,math\n",
    "import tensorflow as tf\n",
    "import array as arr\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as image\n",
    "%matplotlib inline\n",
    "%load_ext tensorboard\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import MaxPool2D, GlobalAveragePooling2D, BatchNormalization, MaxPooling2D, Conv2D\n",
    "from tensorflow.keras.layers import Activation, Flatten, Dropout, Dense, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.xception import decode_predictions\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "from tensorflow.keras.applications.xception import Xception, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/project/dogs/Images'\n",
    "num_of_categories = 120\n",
    "image_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 breeds\n"
     ]
    }
   ],
   "source": [
    "breed_list = sorted(os.listdir(image_path))\n",
    "num_classes = len(breed_list)\n",
    "print(\"{} breeds\".format(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_maps = {}\n",
    "label_maps_rev = {}\n",
    "for i, v in enumerate(breed_list):\n",
    "    label_maps.update({v: i})\n",
    "    label_maps_rev.update({i : v})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paths_and_labels():\n",
    "    pic_paths1 = list()\n",
    "    num_labels1 = list()\n",
    "    pic_paths2 = list()\n",
    "    num_labels2 = list()\n",
    "    mat_file1 = sio.loadmat('/project/dogs/lists/train_list.mat')\n",
    "    train_list = mat_file1['file_list']\n",
    "    mat_file2 = sio.loadmat('/project/dogs/lists/test_list.mat')\n",
    "    test_list = mat_file2['file_list']\n",
    "\n",
    "    for item in train_list:\n",
    "        splited = np.char.split(item[0],sep = '/')\n",
    "        dirs = \"/project/dogs/Images/\" + splited[0][0] +\"/\" + splited[0][1]\n",
    "        pic_paths1.append(dirs)\n",
    "        y_name = splited[0][0]       \n",
    "        num_labels1.append(label_maps[y_name])\n",
    "\n",
    "    for item in test_list:\n",
    "        splited = np.char.split(item[0],sep = '/')\n",
    "        dirs = \"/project/dogs/Images/\" + splited[0][0] +\"/\" + splited[0][1]\n",
    "        pic_paths2.append(dirs)\n",
    "        y_name = splited[0][0]       \n",
    "        num_labels2.append(label_maps[y_name])\n",
    "\n",
    "    return pic_paths1, np.asarray(num_labels1), pic_paths2, np.asarray(num_labels2)                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = paths_and_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 12000, 8580, 8580)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train),len(y_train),len(x_test),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageGenerator(Sequence):   \n",
    "    def __init__(self, paths, targets, batch_size, shape, augment=False):\n",
    "        self.paths = paths\n",
    "        self.targets = targets\n",
    "        self.batch_size = batch_size\n",
    "        self.shape = shape\n",
    "        self.augment = augment\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.paths) / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_paths = self.paths[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
    "        x = np.zeros((len(batch_paths), self.shape[0], self.shape[1], self.shape[2]), dtype=np.float32)\n",
    "        y = np.zeros((self.batch_size))\n",
    "        for i, path in enumerate(batch_paths):\n",
    "            x[i] = self.__load_image(path)\n",
    "        y = self.targets[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
    "        return x, y\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for item in (self[i] for i in range(len(self))):\n",
    "            yield item\n",
    "            \n",
    "    def __load_image(self, path):\n",
    "        image = cv2.imread(path)\n",
    "        image = preprocess_input(image)\n",
    "        if self.augment:\n",
    "            sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "            seq = iaa.Sequential([\n",
    "                iaa.OneOf([\n",
    "                    iaa.Fliplr(0.5),\n",
    "            iaa.Flipud(0.5),\n",
    "                    iaa.Crop(percent=(0, 0.1)),\n",
    "                    iaa.Sometimes(0.5,),\n",
    "                    iaa.LinearContrast((0.75, 1.5)),\n",
    "                    iaa.Affine(\n",
    "                        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "                        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "                        rotate=(-45, 45),\n",
    "                        shear=(-8, 8)\n",
    "                    )\n",
    "                ])\n",
    "            ], random_order=True)\n",
    "            image = seq.augment_image(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "x_train,y_train = shuffle(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 32\n",
    "train_ds = ImageGenerator(x_train, y_train, batch_size=batch, shape=(image_size, image_size,3), augment=True)\n",
    "test_ds = ImageGenerator(x_test, y_test, batch_size=batch, shape=(image_size, image_size,3), augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.xception.Xception(weights='imagenet',include_top=False, pooling='avg')#Summary of Xception Model\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_dim = 5 * 5 * 2048\n",
    "\n",
    "model = Sequential(base_model)\n",
    "model.add(Dense(1032, activation='relu',input_dim=flat_dim))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(120, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_init = 5e-05\n",
    "###################\n",
    "def lr_scheduler(epoch):\n",
    "    epoch += 1\n",
    "    if epoch == 1:\n",
    "        return learning_rate_init\n",
    "    \n",
    "    elif epoch >= 2 and epoch <= 40:\n",
    "        return (0.2*epoch**3)*math.exp(-0.45*epoch)*learning_rate_init\n",
    "    \n",
    "    else:\n",
    "        return lr_scheduler(40-1)\n",
    "stage = [i for i in range(0,25)]\n",
    "learning_rate = [lr_scheduler(x) for x in stage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience = 6, mode='max', min_delta=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, steps_per_epoch=len(x_train)/batch, validation_data=test_ds,  \n",
    "                              validation_steps=len(x_test)/batch, epochs=5, callbacks=[scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(\"weights2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              optimizer = tf.keras.optimizers.RMSprop(lr=5e-05),\n",
    "              metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model:  133\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 90\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable =  False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Model)             (None, 2048)              20861480  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1032)              2114568   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1032)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               528896    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 120)               30840     \n",
      "=================================================================\n",
      "Total params: 23,667,112\n",
      "Trainable params: 13,897,952\n",
      "Non-trainable params: 9,769,160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_fine = model.fit(train_ds, steps_per_epoch=len(x_train)/batch, validation_data=test_ds,  \n",
    "                              validation_steps=len(x_test)/batch, epochs=total_epochs)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"weights3.3_ft.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 19s 193ms/step - loss: 0.3998 - accuracy: 0.8856\n",
      "Test results \n",
      " Loss: 0.39977753162384033 \n",
      " Accuracy 0.8856250047683716\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_ds,steps=int(100))\n",
    "\n",
    "print(\"Test results \\n Loss:\",test_loss,'\\n Accuracy',test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(x_test)/batch\n",
    "predict = model.predict(test_ds,steps=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_cls_idx = predict.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.84      0.83      0.83        52\\n           1       0.95      0.89      0.92        85\\n           2       0.96      0.93      0.95       152\\n           3       0.86      0.90      0.88        49\\n           4       0.84      0.88      0.86       114\\n           5       0.94      0.95      0.95        88\\n           6       0.95      0.98      0.96        96\\n           7       0.87      0.85      0.86        72\\n           8       0.81      0.78      0.79        72\\n           9       0.99      0.99      0.99       139\\n          10       0.90      0.95      0.92        75\\n          11       0.86      0.88      0.87        95\\n          12       0.94      0.86      0.90        87\\n          13       0.89      0.87      0.88        71\\n          14       0.85      0.85      0.85        59\\n          15       0.77      0.77      0.77        53\\n          16       0.76      0.74      0.75        57\\n          17       0.77      0.90      0.83        48\\n          18       0.96      0.94      0.95        51\\n          19       0.87      0.91      0.89       118\\n          20       0.88      0.94      0.91        82\\n          21       0.86      0.79      0.83        87\\n          22       0.94      0.88      0.91        88\\n          23       0.99      0.98      0.98        96\\n          24       0.81      0.94      0.87        51\\n          25       0.99      0.96      0.97       100\\n          26       0.93      0.87      0.90       132\\n          27       0.97      0.97      0.97        60\\n          28       0.76      0.67      0.71        55\\n          29       0.70      0.75      0.72        64\\n          30       1.00      1.00      1.00        82\\n          31       0.93      0.92      0.92        72\\n          32       0.92      0.91      0.92        79\\n          33       0.78      0.90      0.83        69\\n          34       0.84      0.78      0.81        72\\n          35       0.93      0.82      0.87        85\\n          36       0.65      0.75      0.70        64\\n          37       0.79      0.81      0.80        57\\n          38       0.90      0.82      0.86        97\\n          39       0.99      0.96      0.98       102\\n          40       0.88      0.78      0.83       102\\n          41       0.84      0.89      0.86        97\\n          42       0.80      0.80      0.80        96\\n          43       0.88      0.96      0.92        80\\n          44       0.96      0.94      0.95        82\\n          45       0.92      0.87      0.90        54\\n          46       0.85      0.89      0.87        57\\n          47       0.85      0.82      0.83        55\\n          48       0.90      0.90      0.90        58\\n          49       0.87      0.89      0.88       106\\n          50       0.76      0.73      0.75        83\\n          51       0.94      0.88      0.91        56\\n          52       0.87      0.96      0.91        69\\n          53       0.77      0.77      0.77        86\\n          54       0.89      0.94      0.92        52\\n          55       0.94      0.96      0.95        51\\n          56       0.81      0.94      0.87        50\\n          57       0.92      0.83      0.87        71\\n          58       0.80      0.94      0.86        67\\n          59       0.88      0.85      0.86        52\\n          60       0.85      0.87      0.86        54\\n          61       0.91      0.82      0.86        61\\n          62       0.88      0.89      0.88        55\\n          63       0.96      0.91      0.93        53\\n          64       0.90      0.85      0.87        52\\n          65       0.91      0.98      0.94        50\\n          66       0.90      0.97      0.93        59\\n          67       0.87      0.90      0.88        50\\n          68       0.90      0.88      0.89        59\\n          69       1.00      0.84      0.91        51\\n          70       0.96      0.94      0.95        50\\n          71       0.87      0.94      0.90        50\\n          72       0.98      0.93      0.95        54\\n          73       0.89      1.00      0.94        50\\n          74       0.84      0.86      0.85        50\\n          75       0.89      0.92      0.91        52\\n          76       0.67      0.70      0.69        53\\n          77       0.98      0.96      0.97        54\\n          78       0.94      0.96      0.95        69\\n          79       0.89      0.89      0.89        57\\n          80       0.79      0.62      0.69        53\\n          81       0.75      0.80      0.78        50\\n          82       0.91      0.82      0.86        50\\n          83       0.76      0.90      0.82        52\\n          84       0.95      0.77      0.85        52\\n          85       0.85      0.90      0.87        50\\n          86       0.87      0.88      0.88        84\\n          87       0.88      0.90      0.89        68\\n          88       0.96      0.97      0.96       118\\n          89       0.61      0.80      0.69        51\\n          90       0.95      0.88      0.91       102\\n          91       0.89      0.92      0.90        51\\n          92       0.94      0.89      0.92        56\\n          93       0.96      0.90      0.93        52\\n          94       0.92      1.00      0.96        59\\n          95       0.96      0.84      0.90        56\\n          96       0.99      0.97      0.98        70\\n          97       0.44      0.56      0.49        50\\n          98       0.84      0.79      0.82        78\\n          99       0.68      0.59      0.63        92\\n         100       0.96      0.96      0.96        50\\n         101       0.96      0.93      0.94       109\\n         102       0.97      0.96      0.96       100\\n         103       0.97      0.97      0.97       110\\n         104       0.93      0.96      0.94        95\\n         105       0.96      0.88      0.92       113\\n         106       0.94      0.99      0.96       118\\n         107       0.95      0.97      0.96       119\\n         108       0.99      0.97      0.98        96\\n         109       0.98      1.00      0.99        58\\n         110       0.91      0.96      0.94        53\\n         111       0.90      0.96      0.93        81\\n         112       0.83      0.73      0.78        55\\n         113       0.73      0.71      0.72        51\\n         114       0.72      0.65      0.69        55\\n         115       0.85      0.97      0.90        59\\n         116       0.98      0.98      0.98        55\\n         117       0.77      0.82      0.79        56\\n         118       0.94      0.98      0.96        50\\n         119       1.00      1.00      1.00        69\\n\\n    accuracy                           0.89      8580\\n   macro avg       0.88      0.88      0.88      8580\\nweighted avg       0.89      0.89      0.89      8580\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_test,preds_cls_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
