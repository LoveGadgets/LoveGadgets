{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "def x_data(list_path):\n",
    "    mat_file = sio.loadmat(list_path)\n",
    "    sorted(mat_file.keys())\n",
    "    array = mat_file['file_list']\n",
    "    data_array = []\n",
    "    for image in array:\n",
    "        splited = np.char.split(image[0],sep = '/')\n",
    "        dirs = \"/Users/Daniel/dogs/Images/\" + splited[0][0] +\"/\" + splited[0][1]\n",
    "        image = Image.open(dirs)\n",
    "        image_sequence = image.getdata()\n",
    "        image_array = np.array(image_sequence)\n",
    "        data_array.append(image_array)\n",
    "    data_array = np.array(data_array)\n",
    "    return data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_data(list_path):\n",
    "    mat_file = sio.loadmat(list_path)\n",
    "    sorted(mat_file.keys())\n",
    "    array = mat_file['file_list']\n",
    "    data_array = []\n",
    "    category_dict = dict()\n",
    "    with open(\"/Users/Daniel/dogs/indexmap.txt\", 'r') as infile:\n",
    "        for line in infile:\n",
    "            line = line.strip().split()\n",
    "            category_dict[line[0]] = line[1]     \n",
    "    for image in array:\n",
    "        splited = np.char.split(image[0],sep = '/')\n",
    "        name = splited[0][0].split(\"-\",1)[1]\n",
    "        category_index = category_dict[name]\n",
    "        data_array.append(int(category_index))\n",
    "    data_array = np.array(data_array)\n",
    "    return data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('/project/dogs/data/xtrain.npy',mmap_mode=\"r\")\n",
    "x_test = np.load('/project/dogs/data/xtest.npy',mmap_mode=\"r\")\n",
    "y_train = np.load('/project/dogs/data/y_train.npy',mmap_mode=\"r\")\n",
    "y_test = np.load('/project/dogs/data/y_test.npy',mmap_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(12000,300,300,3)\n",
    "x_test = x_test.reshape(8580,300,300,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_cat_train = to_categorical(y_train,120)\n",
    "y_cat_test = to_categorical(y_test,120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_cat_train = to_categorical(y_train,120)\n",
    "y_cat_test = to_categorical(y_test,120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(4,4),input_shape=(300, 300, 3), activation='relu',))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(4,4),input_shape=(300, 300, 3), activation='relu',))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(4,4),input_shape=(300, 300, 3), activation='relu',))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(4,4),input_shape=(300, 300, 3), activation='relu',))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(120, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train,y_cat_train,epochs=30,validation_data=(x_test,y_cat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
